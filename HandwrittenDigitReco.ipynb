{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: np_utils in /Users/nizarsmac/anaconda3/lib/python3.11/site-packages (0.6.0)\n",
      "Requirement already satisfied: numpy>=1.0 in /Users/nizarsmac/anaconda3/lib/python3.11/site-packages (from np_utils) (1.26.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.datasets import mnist\n",
    "import np_utils\n",
    "from keras import layers\n",
    "from keras.src.utils.np_utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_model(num_pixels, num_classes):\n",
    "\n",
    "    #TODO - Application 1 - Step 6a - Initialize the sequential model\n",
    "    model = keras.models.Sequential()\n",
    "\n",
    "    #TODO - Application 1 - Step 6b - Define a hidden dense layer with 8 neurons\n",
    "    model.add(layers.Dense(8, input_dim=num_pixels, kernel_initializer='normal', activation='relu'))\n",
    "    \n",
    "    #TODO - Application 1 - Step 6c - Define the output dense layer\n",
    "    model.add(layers.Dense(num_classes, kernel_initializer='normal', activation='softmax'))\n",
    "\n",
    "    # TODO - Application 1 - Step 6d - Compile the model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainAndPredictMLP(X_train, Y_train, X_test, Y_test):\n",
    "\n",
    "    #TODO - Application 1 - Step 3 - Reshape the MNIST dataset - Transform the images to 1D vectors of floats (28x28 pixels  to  784 elements)\n",
    "    num_pixels = X_train.shape[1] * X_train.shape[1]\n",
    "    X_train = X_train.reshape((X_train.shape[0], num_pixels)).astype('float32') \n",
    "    X_test = X_test.reshape((X_test.shape[0], num_pixels)).astype('float32')\n",
    "    \n",
    "    #TODO - Application 1 - Step 4 - Normalize the input values\n",
    "    X_train = X_train / 255\n",
    "    X_test = X_test / 255\n",
    "    \n",
    "    #TODO - Application 1 - Step 5 - Transform the classes labels into a binary matrix\n",
    "    Y_train = to_categorical(Y_train)\n",
    "    Y_test = to_categorical(Y_test)\n",
    "    num_classes = Y_test.shape[1]\n",
    "\n",
    "    #TODO - Application 1 - Step 6 - Build the model architecture - Call the baseline_model function\n",
    "    model = baseline_model(num_pixels, num_classes)\n",
    "    \n",
    "    #TODO - Application 1 - Step 7 - Train the model\n",
    "    model.fit(X_train, Y_train, validation_data=(X_test, Y_test), epochs=10, batch_size=200, verbose=2)\n",
    "\n",
    "    # Save the model's weights \n",
    "    model.save_weights('mnist_model_weights.h5')\n",
    "    \n",
    "    #TODO - Application 1 - Step 8 - System evaluation - compute and display the prediction error\n",
    "    scores = model.evaluate(X_test, Y_test, verbose=0) \n",
    "    print(\"Baseline Error: {:.2f}\".format(100-scores[1]*100))\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN_model(input_shape, num_classes):\n",
    "\n",
    "    # TODO - Application 2 - Step 5a - Initialize the sequential model\n",
    "    model = None   #Modify this\n",
    "\n",
    "    #TODO - Application 2 - Step 5b - Create the first hidden layer as a convolutional layer\n",
    "\n",
    "    #TODO - Application 2 - Step 5c - Define the pooling layer\n",
    "\n",
    "    #TODO - Application 2 - Step 5d - Define the Dropout layer\n",
    "\n",
    "    #TODO - Application 2 - Step 5e - Define the flatten layer\n",
    "\n",
    "    #TODO - Application 2 - Step 5f - Define a dense layer of size 128\n",
    "\n",
    "    #TODO - Application 2 - Step 5g - Define the output layer\n",
    "\n",
    "    #TODO - Application 2 - Step 5h - Compile the model\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainAndPredictCNN(X_train, Y_train, X_test, Y_test):\n",
    "\n",
    "    #TODO - Application 2 - Step 2 - reshape the data to be of size [samples][width][height][channels]\n",
    "\n",
    "    #TODO - Application 2 - Step 3 - normalize the input values from 0-255 to 0-1\n",
    "\n",
    "    #TODO - Application 2 - Step 4 - One hot encoding - Transform the classes labels into a binary matrix\n",
    "\n",
    "    #TODO - Application 2 - Step 5 - Call the cnn_model function\n",
    "    model = None   #Modify this\n",
    "\n",
    "    #TODO - Application 2 - Step 6 - Train the model\n",
    "\n",
    "    #TODO - Application 2 - Step 8 - Final evaluation of the model - compute and display the prediction error\n",
    "\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "\n",
    "    #TODO - Application 1 - Step 1 - Load the MNIST dataset in Keras\n",
    "    (X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
    "    #TODO - Application 1 - Step 2 - Train and predict on a MLP - Call the trainAndPredictMLP function\n",
    "    trainAndPredictMLP(X_train, Y_train, X_test, Y_test)\n",
    "    #TODO - Application 2 - Step 1 - Train and predict on a CNN - Call the trainAndPredictCNN function\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "300/300 - 0s - loss: 1.2029 - accuracy: 0.6489 - val_loss: 0.5803 - val_accuracy: 0.8330 - 491ms/epoch - 2ms/step\n",
      "Epoch 2/10\n",
      "300/300 - 0s - loss: 0.4899 - accuracy: 0.8620 - val_loss: 0.4061 - val_accuracy: 0.8845 - 215ms/epoch - 716us/step\n",
      "Epoch 3/10\n",
      "300/300 - 0s - loss: 0.3847 - accuracy: 0.8923 - val_loss: 0.3503 - val_accuracy: 0.8997 - 209ms/epoch - 697us/step\n",
      "Epoch 4/10\n",
      "300/300 - 0s - loss: 0.3450 - accuracy: 0.9035 - val_loss: 0.3262 - val_accuracy: 0.9077 - 209ms/epoch - 696us/step\n",
      "Epoch 5/10\n",
      "300/300 - 0s - loss: 0.3253 - accuracy: 0.9090 - val_loss: 0.3129 - val_accuracy: 0.9120 - 210ms/epoch - 699us/step\n",
      "Epoch 6/10\n",
      "300/300 - 0s - loss: 0.3137 - accuracy: 0.9114 - val_loss: 0.3041 - val_accuracy: 0.9145 - 204ms/epoch - 680us/step\n",
      "Epoch 7/10\n",
      "300/300 - 0s - loss: 0.3048 - accuracy: 0.9148 - val_loss: 0.2996 - val_accuracy: 0.9157 - 209ms/epoch - 696us/step\n",
      "Epoch 8/10\n",
      "300/300 - 0s - loss: 0.2989 - accuracy: 0.9167 - val_loss: 0.2990 - val_accuracy: 0.9148 - 208ms/epoch - 693us/step\n",
      "Epoch 9/10\n",
      "300/300 - 0s - loss: 0.2940 - accuracy: 0.9181 - val_loss: 0.2920 - val_accuracy: 0.9184 - 204ms/epoch - 681us/step\n",
      "Epoch 10/10\n",
      "300/300 - 0s - loss: 0.2900 - accuracy: 0.9192 - val_loss: 0.2923 - val_accuracy: 0.9172 - 211ms/epoch - 704us/step\n",
      "Baseline Error: 8.28\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
