{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: np_utils in /Users/nizarsmac/anaconda3/lib/python3.11/site-packages (0.6.0)\n",
      "Requirement already satisfied: numpy>=1.0 in /Users/nizarsmac/anaconda3/lib/python3.11/site-packages (from np_utils) (1.26.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.datasets import mnist\n",
    "import np_utils\n",
    "from keras import layers\n",
    "from keras.src.utils.np_utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_model(num_pixels, num_classes):\n",
    "\n",
    "    #TODO - Application 1 - Step 6a - Initialize the sequential model\n",
    "    model = keras.models.Sequential()\n",
    "\n",
    "    #TODO - Application 1 - Step 6b - Define a hidden dense layer with 8 neurons\n",
    "    model.add(layers.Dense(8, input_dim=num_pixels, kernel_initializer='normal', activation='relu'))\n",
    "    \n",
    "    #TODO - Application 1 - Step 6c - Define the output dense layer\n",
    "    model.add(layers.Dense(num_classes, kernel_initializer='normal', activation='softmax'))\n",
    "\n",
    "    # TODO - Application 1 - Step 6d - Compile the model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainAndPredictMLP(X_train, Y_train, X_test, Y_test):\n",
    "\n",
    "    #TODO - Application 1 - Step 3 - Reshape the MNIST dataset - Transform the images to 1D vectors of floats (28x28 pixels  to  784 elements)\n",
    "    num_pixels = X_train.shape[1] * X_train.shape[1]\n",
    "    X_train = X_train.reshape((X_train.shape[0], num_pixels)).astype('float32') \n",
    "    X_test = X_test.reshape((X_test.shape[0], num_pixels)).astype('float32')\n",
    "    \n",
    "    #TODO - Application 1 - Step 4 - Normalize the input values\n",
    "    X_train = X_train / 255\n",
    "    X_test = X_test / 255\n",
    "    \n",
    "    #TODO - Application 1 - Step 5 - Transform the classes labels into a binary matrix\n",
    "    Y_train = to_categorical(Y_train)\n",
    "    Y_test = to_categorical(Y_test)\n",
    "    num_classes = Y_test.shape[1]\n",
    "\n",
    "    #TODO - Application 1 - Step 6 - Build the model architecture - Call the baseline_model function\n",
    "    model = baseline_model(num_pixels, num_classes)\n",
    "    \n",
    "    #TODO - Application 1 - Step 7 - Train the model\n",
    "    model.fit(X_train, Y_train, validation_data=(X_test, Y_test), epochs=10, batch_size=200, verbose=2)\n",
    "\n",
    "    # Save the model's weights \n",
    "    model.save_weights('mnist_model_weights.h5')\n",
    "    \n",
    "    #TODO - Application 1 - Step 8 - System evaluation - compute and display the prediction error\n",
    "    scores = model.evaluate(X_test, Y_test, verbose=0) \n",
    "    print(\"Baseline Error: {:.2f}\".format(100-scores[1]*100))\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN_model(input_shape, num_classes):\n",
    "\n",
    "    # TODO - Application 2 - Step 5a - Initialize the sequential model\n",
    "    model = keras.models.Sequential()\n",
    "\n",
    "    #TODO - Application 2 - Step 5b - Create the first hidden layer as a convolutional layer\n",
    "    model.add(layers.Conv2D(30, kernel_size=(5, 5), activation='relu', input_shape=input_shape))\n",
    "    \n",
    "    #TODO - Application 2 - Step 5c - Define the pooling layer\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    #Create a hidden layer as a convolutional layer\n",
    "    model.add(layers.Conv2D(15, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
    "\n",
    "    #Define another pooling layer\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    #TODO - Application 2 - Step 5d - Define the Dropout layer\n",
    "    model.add(layers.Dropout(0.2))\n",
    "\n",
    "    #TODO - Application 2 - Step 5e - Define the flatten layer\n",
    "    model.add(layers.Flatten())\n",
    "\n",
    "    #TODO - Application 2 - Step 5f - Define a dense layer of size 128\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "\n",
    "    #Define a dense layer of size 50\n",
    "    model.add(layers.Dense(50, activation='relu'))\n",
    "\n",
    "    #TODO - Application 2 - Step 5g - Define the output layer\n",
    "    model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    #TODO - Application 2 - Step 5h - Compile the model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainAndPredictCNN(X_train, Y_train, X_test, Y_test):\n",
    "\n",
    "    #TODO - Application 2 - Step 2 - reshape the data to be of size [samples][width][height][channels]\n",
    "    X_train = X_train.reshape((X_train.shape[0], 28, 28, 1))\n",
    "    X_test = X_test.reshape((X_test.shape[0], 28, 28, 1))\n",
    "\n",
    "    #TODO - Application 2 - Step 3 - normalize the input values from 0-255 to 0-1\n",
    "    X_train = X_train / 255\n",
    "    X_test = X_test / 255\n",
    "    \n",
    "    #TODO - Application 2 - Step 4 - One hot encoding - Transform the classes labels into a binary matrix\n",
    "    Y_train = to_categorical(Y_train)\n",
    "    Y_test = to_categorical(Y_test)\n",
    "\n",
    "    #TODO - Application 2 - Step 5 - Call the cnn_model function\n",
    "    input_shape = (28, 28, 1)\n",
    "    num_classes = 10\n",
    "    model = CNN_model(input_shape, num_classes) \n",
    "    \n",
    "    #TODO - Application 2 - Step 6 - Train the model\n",
    "    model.fit(X_train, Y_train, validation_data=(X_test, Y_test), epochs=5, batch_size=200, verbose=2)\n",
    "\n",
    "    #TODO - Application 2 - Step 8 - Final evaluation of the model - compute and display the prediction error\n",
    "    #Evaluate the model on the test data\n",
    "    scores = model.evaluate(X_test, Y_test, verbose=0)\n",
    "\n",
    "    # Print the classification error rate\n",
    "    print(f\"Classification Error Rate: {(1-scores[1]) * 100:.2f}%\")\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "\n",
    "    #TODO - Application 1 - Step 1 - Load the MNIST dataset in Keras\n",
    "    (X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
    "    \n",
    "    #TODO - Application 1 - Step 2 - Train and predict on a MLP - Call the trainAndPredictMLP function\n",
    "    # trainAndPredictMLP(X_train, Y_train, X_test, Y_test)\n",
    "    \n",
    "    #TODO - Application 2 - Step 1 - Train and predict on a CNN - Call the trainAndPredictCNN function\n",
    "    trainAndPredictCNN(X_train, Y_train, X_test, Y_test)\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "300/300 - 11s - loss: 0.3583 - accuracy: 0.8907 - val_loss: 0.0792 - val_accuracy: 0.9754 - 11s/epoch - 38ms/step\n",
      "Epoch 2/5\n",
      "300/300 - 11s - loss: 0.0913 - accuracy: 0.9716 - val_loss: 0.0423 - val_accuracy: 0.9862 - 11s/epoch - 38ms/step\n",
      "Epoch 3/5\n",
      "300/300 - 11s - loss: 0.0665 - accuracy: 0.9787 - val_loss: 0.0412 - val_accuracy: 0.9860 - 11s/epoch - 38ms/step\n",
      "Epoch 4/5\n",
      "300/300 - 11s - loss: 0.0544 - accuracy: 0.9827 - val_loss: 0.0326 - val_accuracy: 0.9895 - 11s/epoch - 38ms/step\n",
      "Epoch 5/5\n",
      "300/300 - 11s - loss: 0.0454 - accuracy: 0.9856 - val_loss: 0.0343 - val_accuracy: 0.9886 - 11s/epoch - 37ms/step\n",
      "Classification Error Rate: 1.14%\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
